<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Datawhale 吃瓜task01概览西瓜书+南瓜书第1、2章 频率派：统计机器学习 贝叶斯派：概率图模型 01绪论1.1引言机器学习：通过计算手段，利用经验来改善系统自身的性能 有了数据，通过某种算法，得到模型，进行预测 1.2基本术语数据： 数据集 样本 特征向量，样本空间 属性  通过某种方法学习 学习 训练  得到模型 有监督学习训练数据有标记信息，如同一个supervisor来指导你的">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/2022/08/15/datawhale%E5%90%83%E7%93%9Ctask01/Datawhale%20%E5%90%83%E7%93%9Ctask01/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Datawhale 吃瓜task01概览西瓜书+南瓜书第1、2章 频率派：统计机器学习 贝叶斯派：概率图模型 01绪论1.1引言机器学习：通过计算手段，利用经验来改善系统自身的性能 有了数据，通过某种算法，得到模型，进行预测 1.2基本术语数据： 数据集 样本 特征向量，样本空间 属性  通过某种方法学习 学习 训练  得到模型 有监督学习训练数据有标记信息，如同一个supervisor来指导你的">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://img-blog.csdn.net/20180814145009595?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTM3MDA4Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20180814145734738?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTM3MDA4Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="http://example.com/2022/08/15/datawhale%E5%90%83%E7%93%9Ctask01/Datawhale%20%E5%90%83%E7%93%9Ctask01/Users/LOIS/AppData/Roaming/Typora/typora-user-images/image-20220815121152850.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2f20b682067b4647800c4381a60be99b.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/09d22d9418f84138a03968c9abf94f9a.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/b70160e94a5d487e82af3d2edf1b9ccd.png">
<meta property="og:image" content="http://example.com/2022/08/15/datawhale%E5%90%83%E7%93%9Ctask01/Datawhale%20%E5%90%83%E7%93%9Ctask01/Users/LOIS/AppData/Roaming/Typora/typora-user-images/image-20220815153635438.png">
<meta property="og:image" content="http://example.com/2022/08/15/datawhale%E5%90%83%E7%93%9Ctask01/Datawhale%20%E5%90%83%E7%93%9Ctask01/Users/LOIS/AppData/Roaming/Typora/typora-user-images/image-20220815153753250.png">
<meta property="og:image" content="http://example.com/2022/08/15/datawhale%E5%90%83%E7%93%9Ctask01/Datawhale%20%E5%90%83%E7%93%9Ctask01/Users/LOIS/AppData/Roaming/Typora/typora-user-images/image-20220815154047944.png">
<meta property="og:image" content="http://example.com/2022/08/15/datawhale%E5%90%83%E7%93%9Ctask01/Datawhale%20%E5%90%83%E7%93%9Ctask01/Users/LOIS/AppData/Roaming/Typora/typora-user-images/image-20220815154143634.png">
<meta property="article:published_time" content="2022-08-15T13:21:14.562Z">
<meta property="article:modified_time" content="2022-08-15T07:52:50.773Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdn.net/20180814145009595?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTM3MDA4Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-datawhale吃瓜task01/Datawhale 吃瓜task01" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/08/15/datawhale%E5%90%83%E7%93%9Ctask01/Datawhale%20%E5%90%83%E7%93%9Ctask01/" class="article-date">
  <time class="dt-published" datetime="2022-08-15T13:21:14.562Z" itemprop="datePublished">2022-08-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Datawhale-吃瓜task01"><a href="#Datawhale-吃瓜task01" class="headerlink" title="Datawhale 吃瓜task01"></a>Datawhale 吃瓜task01</h1><p>概览西瓜书+南瓜书第1、2章</p>
<p>频率派：统计机器学习</p>
<p>贝叶斯派：概率图模型</p>
<h2 id="01绪论"><a href="#01绪论" class="headerlink" title="01绪论"></a>01绪论</h2><h3 id="1-1引言"><a href="#1-1引言" class="headerlink" title="1.1引言"></a>1.1引言</h3><p>机器学习：通过计算手段，利用经验来改善系统自身的性能</p>
<p>有了数据，通过某种算法，得到模型，进行预测</p>
<h3 id="1-2基本术语"><a href="#1-2基本术语" class="headerlink" title="1.2基本术语"></a>1.2基本术语</h3><h4 id="数据："><a href="#数据：" class="headerlink" title="数据："></a>数据：</h4><blockquote>
<p>数据集</p>
<p>样本</p>
<p>特征向量，样本空间</p>
<p>属性</p>
</blockquote>
<h4 id="通过某种方法学习"><a href="#通过某种方法学习" class="headerlink" title="通过某种方法学习"></a>通过某种方法学习</h4><blockquote>
<p>学习 训练</p>
</blockquote>
<h4 id="得到模型"><a href="#得到模型" class="headerlink" title="得到模型"></a>得到模型</h4><blockquote>
<h5 id="有监督学习"><a href="#有监督学习" class="headerlink" title="有监督学习"></a>有监督学习</h5><p>训练数据有标记信息，如同一个supervisor来<strong>指导</strong>你的行动</p>
<p> 分类:二分类、多分类</p>
<p>回归：预测值是连续值</p>
</blockquote>
<blockquote>
<h5 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h5><p>训练数据没有标记信息，但需要训练得到数据之中的 “隐式” 标记比如书中的<strong>聚类</strong></p>
<p>聚类 不知道分几类，机器自己分，每个组称为一个簇</p>
</blockquote>
<h4 id="进行预测"><a href="#进行预测" class="headerlink" title="进行预测"></a>进行预测</h4><p>测试</p>
<p>测试样本 </p>
<p>泛化能力</p>
<h3 id="1-3假设空间"><a href="#1-3假设空间" class="headerlink" title="1.3假设空间"></a>1.3假设空间</h3><p>归纳</p>
<p>演绎</p>
<h3 id="1-4归纳偏好"><a href="#1-4归纳偏好" class="headerlink" title="1.4归纳偏好"></a>1.4归纳偏好</h3><p>同一个数据集训练出的不同模型，如何选择模型</p>
<p><strong>奥卡姆剃刀原理</strong>，选最简单的那个，也有其他理解</p>
<p>如非必要，误增实体。</p>
<p>那问题来了，如何界定何为<strong>必要</strong>，这又是一个麻烦的问题。事实上，书上所给的曲线拟合的例子，在拟合参数变多时，可以通过<strong>正则化（regulization）</strong>或者<strong>增加数据个数</strong>来很好的减轻过拟合的程度</p>
<p>**NFL（No Free Lunch Theorem)**：通过公式的推导，我们发现总误差竟然与学习算法无关，对于任意两个学习算法，无论哪个算法更加”聪明“或者更加”笨拙”，它们的期望性能竟然相同。</p>
<p>首先，我们是这样定义一个假设函数h对一个样本点x的预测误差的：预测值h(x)与真实值f(x)一致则误差为0，不一致则误差为1，即I(h(x)≠f(x))，由于x是一个随机变量，那么这个误差值也是一个随机变量，取值为0或1，其在训练集之外的所有样本上的期望可以看作假设函数h在训练集之外的所有样本上预测的错误率，即：<br><img src="https://img-blog.csdn.net/20180814145009595?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTM3MDA4Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img"></p>
<p>在算法La的假设空间中可能会存在多个假设函数与训练集一致，每一个假设函数的产生是有概率的，令算法La在训练数据集X上产生某个假设h的概率为P(h|X, La)，那么，我们接下来要做的是定义算法La在“训练集之外的所有样本上的误差”，而不只是La产生的一个假设h的误差。</p>
<p>我们已经定义了假设函数h在训练集之外的所有样本上的误差，由于h是算法La以概率P(h|X, La)产生的，那么我们可以定义算法La的误差为所有可能的h的误差的期望，即：</p>
<p><img src="https://img-blog.csdn.net/20180814145734738?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTM3MDA4Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img"></p>
<p>这里考虑的是二分类问题，而且假设真实目标函数f可以是任何输入空间X到输出空间{0, 1}的映射，那么整个函数空间的大小就应该是2^|X|。（指数）</p>
<p> 假设在整个函数空间中所有可能的目标函数f是均匀分布的</p>
<p>所以示性函数这一项可以直接将其变成期望提出来</p>
<p><img src="/2022/08/15/datawhale%E5%90%83%E7%93%9Ctask01/Datawhale%20%E5%90%83%E7%93%9Ctask01/Users\LOIS\AppData\Roaming\Typora\typora-user-images\image-20220815121152850.png" alt="image-20220815121152850"></p>
<p><strong>脱离具体问题谈论算法好坏没有意义，就像脱离具体问题谈数据结构的好坏一样。（例如堆和二叉搜索树）</strong></p>
<h2 id="02模型评估与选择"><a href="#02模型评估与选择" class="headerlink" title="02模型评估与选择"></a>02模型评估与选择</h2><h3 id="一种训练集一种算法"><a href="#一种训练集一种算法" class="headerlink" title="一种训练集一种算法"></a>一种训练集一种算法</h3><h3 id="2-1经验误差与过拟合"><a href="#2-1经验误差与过拟合" class="headerlink" title="2.1经验误差与过拟合"></a>2.1经验误差与过拟合</h3><ul>
<li><p><strong>错误率（error rate）</strong>：分类错误的样本数占样本总数的比例。E&#x3D;a&#x2F;m m个样本，a个样本分类错误</p>
</li>
<li><p><strong>精度（accuracy）</strong>：&#x3D;1−错误率&#x3D;1−E</p>
</li>
<li><p><strong>误差（error）</strong>：学习器的实际预测输出与样本的真实输出之间的差异</p>
</li>
</ul>
<p>​	<strong>训练误差（training error）</strong>、<strong>经验误差（empirical error）</strong>：在训练集上的误差。</p>
<p>​	<strong>泛化误差（generalization error）</strong>：在新样本上的误差</p>
<blockquote>
<p> 我们希望得到泛化误差小的学习器，我们可以学习一个经验误差小的学习器，但是当经验误差为0时，这个学习器在多数情况下都不好。</p>
</blockquote>
<ul>
<li><p><strong>过拟合（overfitting）</strong>：学习器把训练样本学得太好了，把一些训练样本自身的一些特点当做了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下</p>
</li>
<li><p><strong>欠拟合（underfitting）</strong>：对训练样本的一般性质尚未学好。</p>
</li>
<li><p><strong>模型选择</strong>：理想的解决方案是对候选模型的泛化误差进行评估，然后选择泛化误差最小的那个模型</p>
<p><img src="https://img-blog.csdnimg.cn/2f20b682067b4647800c4381a60be99b.png" alt="请添加图片描述"></p>
</li>
</ul>
<h3 id="2-2评估方法"><a href="#2-2评估方法" class="headerlink" title="2.2评估方法"></a>2.2评估方法</h3><p>通过实验对学习器的泛化误差进行评估。</p>
<ul>
<li><p><strong>测试集（testing set）</strong>：测试集中的样本是从样本真实分布中独立同分布采样而来。且测试集与训练集尽量互斥。</p>
</li>
<li><p><strong>测试误差（testing error）</strong>：用作泛化误差的近似。</p>
<p>对数据集D进行处理，从中产生<strong>训练集S</strong> 和<strong>测试集T</strong> 。</p>
</li>
</ul>
<h4 id="2-2-1留出法（hold-out）"><a href="#2-2-1留出法（hold-out）" class="headerlink" title="2.2.1留出法（hold-out）"></a>2.2.1留出法（hold-out）</h4><p>将D划分成两个互斥的集合，D &#x3D; S ⋃ T , S ⋂ T &#x3D; ∅ .在S上训练，用T估计泛化误差。</p>
<p>数据集的划分要保持数据分布的一致性，避免因数据划分引入额外的偏差，如在分类任务重要保持样本类别比例相似。通常采用<strong>“分层采样”（stratified sampling）</strong>。</p>
<p>不同的划分会导致不同的训练、测试集，同时，模型评估的方式也会有差别。因此，在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作为评估结果。</p>
<p>留出法的缺点是：若训练集S包含绝大多是样本，则训练出的模型可能更接近于用D训练除的模型，但由于T比较小，评估结果不准确；若令测试集T多包含一些样本，则S与D的差别更大了，从而降低了评估结果的<strong>保真性（fidelity）</strong>。</p>
<p>这个缺点没有完美的解决方案，常见做法是将大约2&#x2F;3~4&#x2F;5的样本用于训练，剩余样本用于测试。</p>
<h4 id="2-2-2交叉验证法（cross-validation）"><a href="#2-2-2交叉验证法（cross-validation）" class="headerlink" title="2.2.2交叉验证法（cross validation）"></a>2.2.2交叉验证法（cross validation）</h4><p>将D划分为k个大小相似的互斥子集，即 D &#x3D; D 1 ⋃ D 2 ⋃ . . . ⋃ D k , D i ⋂ D j &#x3D; ∅ ( i &#x3D;̸ j ) </p>
<p>每个子集D i 都尽可能保持数据分布的一致性：即从D中分层采样得到。</p>
<p>每次用k-1个子集的并集作为S，剩下的那一个作为T</p>
<p>因此可以进行k次训练和测试，最后返回的是这k个测试结果的均值。</p>
<p>交叉验证法评估结果的稳定性和保真性很大程度上决定于k的取值，为强调这点，通常把交叉验证称为“k折交叉验证”（k-fold cross validation），k常取10，此时称为10折交叉验证。<br><img src="https://img-blog.csdnimg.cn/09d22d9418f84138a03968c9abf94f9a.png" alt="请添加图片描述"></p>
<p>与留出法相似，将数据集D划分为k个子集同样存在很多划分方式。为了减小英样本划分不同引入的误差，k折交叉验证通常要随机使用不同的划分重复p次，最终的评估结果是这p次k折交叉验证结果的均值。</p>
<p>若D中含有m个样本，若令k&#x3D;m，则得到了交叉验证的特例：<strong>留一法（Leave-One-Out，简称LOO）</strong>。</p>
<p>LOO不受随机样本划分方式影响，因为m个样本只有唯一的方式划分为m个子集——每个子集包含一个样本。LOO使用的S与D相比只缺少了一个样本，这就使得在绝大多数情况下，LOO的评估比较准确；缺点是在D比较庞大的时候，计算开销很大。</p>
<h4 id="2-2-3自助法（bootstrapping）"><a href="#2-2-3自助法（bootstrapping）" class="headerlink" title="2.2.3自助法（bootstrapping）"></a>2.2.3自助法（bootstrapping）</h4><p>我们一直都希望评估的是使用D训练出的模型，除了LOO受训练样本规模变化的影响较小，上述两种方法都是使用D的一部分用于训练。</p>
<p>而自助法可以减少驯良样本规模不同造成的影响，同时高效的进行实验估计。</p>
<p>给定包含m个样本的数据集D，对他进行采样产生数据集D ′ ：每次随机从D中挑选一个样本，将其拷贝放入D ′  ,然后将该样本放回D，使得该样本在下次采样时仍可能被采样到。<br>重复采样m次，我们就获得了包含m个样本的数据集D ′ </p>
<p>显然，有一部分样本不会在D ′ D\primeD′中出现，而另一部分会出现多次。</p>
<p>在m次采样中始终不被采样到的概率是( 1 − 1 m ) ^m  ，取极限：lim ⁡ m → ∞ ( 1 − 1&#x2F; m ) ^m ↦ 1&#x2F; e ≈ 0.368</p>
<p>通过自助采样，D中约有36.8%的样本未出现在D ′ D\primeD′中，于是我们可以将D ′ 作为训练集S，D − D ′作为测试集T.</p>
<p>这样的测试结果称为<strong>外包估计（out-of-bag estimate）</strong></p>
<p><strong>优点</strong>：</p>
<ol>
<li>在数据集小、难以有效划分训练、测试集时很有用；</li>
<li>自助法能从初始数据集中产生多个不同的训练集，这对集成学习有很大好处。</li>
</ol>
<p><strong>缺点</strong>：</p>
<ol>
<li>改变了初始数据集的分布，这会引入估计误差。</li>
</ol>
<p>在数据量足够的时候，留出法和交叉验证法更常用。</p>
<h4 id="2-2-4-调参与最终模型"><a href="#2-2-4-调参与最终模型" class="headerlink" title="2.2.4 调参与最终模型"></a>2.2.4 调参与最终模型</h4><ul>
<li><p><strong>调参（parameter tuning）：</strong></p>
<p>参数配置不同，模型的性能往往有显著差别。因此，在模型评估与选择时，除了算法选择，还要对算法参数设定。</p>
</li>
</ul>
<p>在包含m各样本的数据集D中，我们只用了一部分数据训练模型，另一部分用于模型评估。</p>
<p>在模型选择完成之后，学习算法和参数配置已选定，此时应该用数据集D重新训练模型，这个训练的过程用了所有m个样本。</p>
<p>通常把学得模型在实际使用过程中遇到的数据成为测试数据，为了加以区分，模型评估与选择中用于评估测试的数据集常称为“验证集”（validation set）。</p>
<ul>
<li>训练集：用来训练模型或确定模型参数</li>
<li>验证集：用来做模型选择（model selection），例如网络结构或者控制模型复杂程度的参数</li>
<li>测试集：检验最终选择最优的模型的性能</li>
</ul>
<h3 id="2-3性能度量"><a href="#2-3性能度量" class="headerlink" title="2.3性能度量"></a>2.3性能度量</h3><ul>
<li><strong>性能度量（performance measure）</strong>：衡量模型泛化能力的评价标准。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/b70160e94a5d487e82af3d2edf1b9ccd.png" alt="请添加图片描述"></p>
<p><strong>回归任务</strong></p>
<ul>
<li><p>均方误差（mean squared error）</p>
<p><img src="/2022/08/15/datawhale%E5%90%83%E7%93%9Ctask01/Datawhale%20%E5%90%83%E7%93%9Ctask01/Users\LOIS\AppData\Roaming\Typora\typora-user-images\image-20220815153635438.png" alt="image-20220815153635438"></p>
<p>对数据分布D和概率密度函数p(·)，均方误差可描述为：</p>
<p><img src="/2022/08/15/datawhale%E5%90%83%E7%93%9Ctask01/Datawhale%20%E5%90%83%E7%93%9Ctask01/Users\LOIS\AppData\Roaming\Typora\typora-user-images\image-20220815153753250.png" alt="image-20220815153753250"></p>
</li>
</ul>
<h4 id="2-3-1错误率与精度（针对分类问题）"><a href="#2-3-1错误率与精度（针对分类问题）" class="headerlink" title="2.3.1错误率与精度（针对分类问题）"></a>2.3.1错误率与精度（针对分类问题）</h4><ul>
<li><p>错误率：</p>
<p><img src="/2022/08/15/datawhale%E5%90%83%E7%93%9Ctask01/Datawhale%20%E5%90%83%E7%93%9Ctask01/Users\LOIS\AppData\Roaming\Typora\typora-user-images\image-20220815154047944.png" alt="image-20220815154047944"></p>
</li>
<li><p>精度：</p>
<p><img src="/2022/08/15/datawhale%E5%90%83%E7%93%9Ctask01/Datawhale%20%E5%90%83%E7%93%9Ctask01/Users\LOIS\AppData\Roaming\Typora\typora-user-images\image-20220815154143634.png" alt="image-20220815154143634"></p>
</li>
</ul>
<h4 id="2-3-2查准率、查全率与F1"><a href="#2-3-2查准率、查全率与F1" class="headerlink" title="2.3.2查准率、查全率与F1"></a>2.3.2查准率、查全率与F1</h4><h3 id="一种训练集多种算法"><a href="#一种训练集多种算法" class="headerlink" title="一种训练集多种算法"></a>一种训练集多种算法</h3><h4 id="2-3-3ROC与AUC"><a href="#2-3-3ROC与AUC" class="headerlink" title="2.3.3ROC与AUC"></a>2.3.3ROC与AUC</h4><h4 id="2-3-4代价敏感错误率与代价曲线"><a href="#2-3-4代价敏感错误率与代价曲线" class="headerlink" title="2.3.4代价敏感错误率与代价曲线"></a>2.3.4代价敏感错误率与代价曲线</h4><h3 id="多种训练集一种算法"><a href="#多种训练集一种算法" class="headerlink" title="多种训练集一种算法"></a>多种训练集一种算法</h3><h3 id="2-5偏差与方法"><a href="#2-5偏差与方法" class="headerlink" title="2.5偏差与方法"></a>2.5偏差与方法</h3><h3 id="测试集上的性能在多大程度上保证真实的性能"><a href="#测试集上的性能在多大程度上保证真实的性能" class="headerlink" title="测试集上的性能在多大程度上保证真实的性能"></a>测试集上的性能在多大程度上保证真实的性能</h3><h3 id="2-4比较检验"><a href="#2-4比较检验" class="headerlink" title="2.4比较检验"></a>2.4比较检验</h3>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/08/15/datawhale%E5%90%83%E7%93%9Ctask01/Datawhale%20%E5%90%83%E7%93%9Ctask01/" data-id="cl6usupk10001pkvqb5ebedj4" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2022/08/15/%E5%9C%B0%E7%90%86%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%A6%E4%B9%A0/%E5%9C%B0%E7%90%86%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%A6%E4%B9%A0/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          (no title)
        
      </div>
    </a>
  
  
    <a href="/2022/08/15/hello-world/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Hello World</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">August 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/08/15/%E5%9C%B0%E7%90%86%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%A6%E4%B9%A0/%E5%9C%B0%E7%90%86%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%A6%E4%B9%A0/">(no title)</a>
          </li>
        
          <li>
            <a href="/2022/08/15/datawhale%E5%90%83%E7%93%9Ctask01/Datawhale%20%E5%90%83%E7%93%9Ctask01/">(no title)</a>
          </li>
        
          <li>
            <a href="/2022/08/15/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>